{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96a974cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense, GlobalAveragePooling1D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "DATA_PATH = './data'\n",
    "SOLUTION_PATH = './solutions'\n",
    "WEIGHTS_PATH = './model_weights'\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6993d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0434a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47cf03a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation\\nWhy the edits made under my usern...\n",
       "1    D'aww! He matches this background colour I'm s...\n",
       "2    Hey man, I'm really not trying to edit war. It...\n",
       "3    \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4    You, sir, are my hero. Any chance you remember...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b1f58b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afefd0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['comment_text'] = train['comment_text'].map(lambda x : clean_text(x))\n",
    "test['comment_text'] = test['comment_text'].map(lambda x : clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed268d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            15294\n",
       "severe_toxic      1595\n",
       "obscene           8449\n",
       "threat             478\n",
       "insult            7877\n",
       "identity_hate     1405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.columns[2:]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83001b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 22:47:16.926518: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-04-28 22:47:17.062988: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2022-04-28 22:47:17.188644: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2022-04-28 22:47:17.207008: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2022-04-28 22:47:18.150018: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2022-04-28 22:47:18.205887: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'activation_13', 'vocab_transform', 'vocab_projector']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'distilbert-base-uncased'\n",
    "max_length = 60\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "distilbert = TFDistilBertModel.from_pretrained(model_name, output_hidden_states=True, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2960e2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4937"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab()['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e04e34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fuck', 'you', 'soy', '##boy', '!']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"fuck you soyboy!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e1f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5fed7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b1dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e973ecfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.95 ms, sys: 0 ns, total: 6.95 ms\n",
      "Wall time: 6.63 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = tokenizer(\n",
    "    text=list(train['comment_text'].values[:5]),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
    "    attention_mask = Input(shape=(max_length,), name='attention_mask', dtype='int32') \n",
    "    inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "    output = distilbert.distilbert(inputs)\n",
    "    \n",
    "    y = concatenate([GlobalAveragePooling1D()(output['hidden_states'][i]) for i in range(-1, -4, -1)])\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=y)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b444be37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 70.7 ms, total: 1min 16s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = tokenizer(\n",
    "    text=list(X.values[:, 0]),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9a9dab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 12min 22s, sys: 1min 26s, total: 3h 13min 49s\n",
      "Wall time: 28min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "output = model.predict(x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
    "                       batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "827cfe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(os.path.join(DATA_PATH, 'train_data_embeddings3'), np.hstack((output, X.values[:, 1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e66d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.load(os.path.join(DATA_PATH, 'train_data_embeddings_250_3072.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e3d4df32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 3072)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0092abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(res, np.hstack((output, X.values[:, 1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1dfed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.load(os.path.join(DATA_PATH, 'train_data_embeddings_125.npy'), allow_pickle=True)\n",
    "y = np.load(os.path.join(DATA_PATH, 'train_label.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c07fb56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159571, 768), (159571, 6))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2f8fe70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.csv',\n",
       " 'train.csv',\n",
       " 'test_labels.csv',\n",
       " 'train_label.npy',\n",
       " 'sample_submission.csv',\n",
       " 'test_data_embeddings_sst_250_2304.npy',\n",
       " 'train_data_embeddings_sst_250_2304.npy']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28319bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.load(os.path.join(DATA_PATH, 'train_data_embeddings_sst_250_2304.npy'), allow_pickle=True)\n",
    "y = np.load(os.path.join(DATA_PATH, 'train_label.npy'), allow_pickle=True)\n",
    "res_test = np.load(os.path.join(DATA_PATH, 'test_data_embeddings_sst_250_2304.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5590f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " polled_embedding (InputLaye  [(None, 2304)]           0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " hidden (Dense)              (None, 64)                147520    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " outputs (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 147,910\n",
      "Trainable params: 147,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_final_model():\n",
    "    input_vec = Input(shape=(768*3,), name='polled_embedding', dtype='float32')\n",
    "         \n",
    "    x = Dense(64, activation='relu', name='hidden')(input_vec)\n",
    "    x = Dropout(0.2)(x)\n",
    "    y = Dense(len(list_classes), activation='sigmoid', name='outputs')(x)\n",
    "\n",
    "    model = Model(inputs=input_vec, outputs=y)\n",
    "    \n",
    "    optimizer = Adam()\n",
    "    loss = BinaryCrossentropy()\n",
    "    metrics = AUC()\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "    return model\n",
    "\n",
    "ffn = get_final_model()\n",
    "ffn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "32e9b071",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, patience, validation_data=()):\n",
    "        super(Callback, self).__init__()\n",
    "        \n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.max_score = 0\n",
    "        self.not_better_count = 0\n",
    "        self.patience = patience\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "        score = roc_auc_score(self.y_val, y_pred)\n",
    "        \n",
    "        print(f'epoch: {epoch}\\nroc_auc: {round(score, 4)}')\n",
    "        logs['roc_auc'] = score\n",
    "        \n",
    "        if score > self.max_score:\n",
    "            self.max_score = score\n",
    "            self.not_better_count = 0\n",
    "            self.model.save(os.path.join(WEIGHTS_PATH, 'ffn'))\n",
    "        else:\n",
    "            self.not_better_count += 1\n",
    "            if self.not_better_count > self.patience:\n",
    "                self.model.stop_training = True\n",
    "                print()\n",
    "                print(f'Best roc_auc score: {round(self.max_score, 4)}')\n",
    "                print('Early Sropping triggered.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8b8394a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1870/1870 [==============================] - 5s 3ms/step - loss: 0.0549 - auc: 0.9765\n",
      "Epoch 2/2\n",
      "1870/1870 [==============================] - 6s 3ms/step - loss: 0.0535 - auc: 0.9777\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(res[:, :768*3], y, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "rocauc_early_stopping = RocAucEvaluation(patience=5,\n",
    "                                         validation_data=(X_test.astype('float32'), \n",
    "                                                          y_test.astype('int8'))\n",
    "                                        )\n",
    "\n",
    "\n",
    "\n",
    "history = ffn.fit(x=X_train.astype('float32'), \n",
    "                  y=y_train.astype('int8'),\n",
    "                  callbacks=[rocauc_early_stopping],\n",
    "                  batch_size=64,\n",
    "                  epochs=2, \n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af6c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "749be6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 23:58:11.728850: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1176477696 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1978/1995 [============================>.] - ETA: 0s - loss: 0.0641 - auc: 0.9672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 23:58:17.038325: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 294128640 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995/1995 [==============================] - 6s 3ms/step - loss: 0.0640 - auc: 0.9673 - val_loss: 0.0575 - val_auc: 0.9727\n",
      "Epoch 2/100\n",
      "1995/1995 [==============================] - 5s 2ms/step - loss: 0.0564 - auc: 0.9753 - val_loss: 0.0549 - val_auc: 0.9776\n",
      "Epoch 3/100\n",
      "1995/1995 [==============================] - 5s 2ms/step - loss: 0.0543 - auc: 0.9776 - val_loss: 0.0531 - val_auc: 0.9769\n",
      "Epoch 4/100\n",
      "1995/1995 [==============================] - 5s 2ms/step - loss: 0.0533 - auc: 0.9782 - val_loss: 0.0527 - val_auc: 0.9774\n",
      "Epoch 5/100\n",
      "1995/1995 [==============================] - 5s 2ms/step - loss: 0.0523 - auc: 0.9793 - val_loss: 0.0526 - val_auc: 0.9793\n",
      "Epoch 6/100\n",
      "1995/1995 [==============================] - 5s 2ms/step - loss: 0.0516 - auc: 0.9800 - val_loss: 0.0519 - val_auc: 0.9777\n",
      "Epoch 7/100\n",
      "1995/1995 [==============================] - 5s 2ms/step - loss: 0.0506 - auc: 0.9807 - val_loss: 0.0511 - val_auc: 0.9788\n",
      "Epoch 8/100\n",
      "1995/1995 [==============================] - 5s 2ms/step - loss: 0.0502 - auc: 0.9812 - val_loss: 0.0521 - val_auc: 0.9791\n",
      "Epoch 9/100\n",
      "1995/1995 [==============================] - 5s 2ms/step - loss: 0.0497 - auc: 0.9815 - val_loss: 0.0528 - val_auc: 0.9752\n",
      "Epoch 10/100\n",
      "1995/1995 [==============================] - 5s 2ms/step - loss: 0.0491 - auc: 0.9817 - val_loss: 0.0518 - val_auc: 0.9781\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "early_stopping = EarlyStopping(monitor='val_auc', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = ffn.fit(x=res[:, :768*3].astype('float32'), \n",
    "                  y=y.astype('int8'),\n",
    "                  validation_split=0.2,\n",
    "                  callbacks=[early_stopping],\n",
    "                  batch_size=64,\n",
    "                  epochs=100, \n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03a8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84a50eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history.history['roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "de20e4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4c414fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.9757575 , 0.99098338, 0.98627091, 0.99345567, 0.98136015,\n",
       "        0.98507512]),\n",
       " 0.9854837884159305)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ffn.predict(X_test.astype('float32'))\n",
    "score = roc_auc_score(y_test.astype('int8'), y_pred, average=None)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9c94a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = tf.keras.models.load_model(os.path.join(WEIGHTS_PATH, 'ffn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd2db18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.97027139, 0.98849069, 0.9812639 , 0.98898447, 0.97704308,\n",
       "        0.977443  ]),\n",
       " 0.9805827541562797)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new\n",
    "y_pred = reconstructed_model.predict(X_test.astype('float32'))\n",
    "score = roc_auc_score(y_test.astype('int8'), y_pred, average=None)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cfd1e3",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa1c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\n",
    "test['comment_text'] = test['comment_text'].map(lambda x : clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f87356",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tokenizer(\n",
    "    text=list(test['comment_text'].values),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12c4197",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
    "                       batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0770d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(os.path.join(DATA_PATH, 'test_data_embeddings'), output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6a07834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test = np.load(os.path.join(DATA_PATH, 'test_data_embeddings_250_3072.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc9870be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 00:00:59.909149: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1411559424 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# predict = reconstructed_model.predict(res_test.astype('float32'), batch_size=16)\n",
    "predict = ffn.predict(res_test[:, :768*3].astype('float32'), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05841ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))\n",
    "sample_submission[list_classes] = predict\n",
    "sample_submission.to_csv(os.path.join(SOLUTION_PATH, 'distilbert_sst_250_2304.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7bad88",
   "metadata": {},
   "source": [
    "# test sst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "38420176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "roc_auc: 0.976\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "epoch: 10\n",
      "roc_auc: 0.9813\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "epoch: 20\n",
      "roc_auc: 0.9811\n",
      "\n",
      "Best roc_auc score: 0.9816\n",
      "Early Sropping triggered.\n",
      "epoch: 0\n",
      "roc_auc: 0.9743\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "epoch: 10\n",
      "roc_auc: 0.9802\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "epoch: 20\n",
      "roc_auc: 0.9803\n",
      "\n",
      "Best roc_auc score: 0.9803\n",
      "Early Sropping triggered.\n",
      "epoch: 0\n",
      "roc_auc: 0.9735\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "epoch: 10\n",
      "roc_auc: 0.9792\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "\n",
      "Best roc_auc score: 0.9799\n",
      "Early Sropping triggered.\n",
      "epoch: 0\n",
      "roc_auc: 0.975\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "epoch: 10\n",
      "roc_auc: 0.9799\n",
      "\n",
      "Best roc_auc score: 0.9801\n",
      "Early Sropping triggered.\n",
      "epoch: 0\n",
      "roc_auc: 0.9753\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "epoch: 10\n",
      "roc_auc: 0.9811\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "INFO:tensorflow:Assets written to: ./model_weights/ffn/assets\n",
      "epoch: 20\n",
      "roc_auc: 0.9797\n",
      "\n",
      "Best roc_auc score: 0.9814\n",
      "Early Sropping triggered.\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=30)\n",
    "\n",
    "predict = np.zeros((res_test.shape[0], len(list_classes)))\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[test_index]\n",
    "    \n",
    "    K.clear_session()\n",
    "    ffn = get_final_model()\n",
    "    \n",
    "    rocauc_early_stopping = RocAucEvaluation(patience=5,\n",
    "                                             validation_data=(X_val_fold.astype('float32'), \n",
    "                                                              y_val_fold.astype('int8')))\n",
    "    ffn.fit(x=X_train_fold.astype('float32'), \n",
    "            y=y_train_fold.astype('int8'),\n",
    "            callbacks=[rocauc_early_stopping],\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs, \n",
    "            verbose=0)\n",
    "    \n",
    "    # load best model\n",
    "    reconstructed_model = tf.keras.models.load_model(os.path.join(WEIGHTS_PATH, 'ffn'))\n",
    "    \n",
    "    predict += reconstructed_model.predict(res_test.astype('float32')) / num_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "89ff7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))\n",
    "sample_submission[list_classes] = predict\n",
    "sample_submission.to_csv(os.path.join(SOLUTION_PATH, 'distilbert_125.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472cb65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "46338f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "blend = pd.read_csv(os.path.join(SOLUTION_PATH, 'old_blend.csv'))\n",
    "blend[list_classes] = (blend[list_classes]*0.9 + sample_submission[list_classes]*0.1)\n",
    "blend.to_csv(os.path.join(SOLUTION_PATH, 'blend_with_bert.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af89c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
